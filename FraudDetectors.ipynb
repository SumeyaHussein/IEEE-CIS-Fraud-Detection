{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"kartik2112/fraud-detection\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#everyone run this block\n",
    "import os\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"kartik2112/fraud-detection\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# List all files in the downloaded directory\n",
    "print(\"Files in dataset directory:\", os.listdir(path))\n",
    "\n",
    "# Load the CSV file (assuming it is named fraudTest.csv in the downloaded files)\n",
    "csv_path = os.path.join(path, \"fraudTest.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spandana runs this\n",
    "import os\n",
    "import pandas as pd\n",
    "#import kagglehub\n",
    "\n",
    "# Download the dataset\n",
    "path = r\"C:\\Users\\Thinking1\\vsc_workspace\\FDS\"\n",
    "\n",
    "# List all files in the downloaded directory\n",
    "print(\"Files in dataset directory:\", os.listdir(path))\n",
    "\n",
    "# Load the CSV file (assuming it is named fraudTest.csv in the downloaded files)\n",
    "csv_path = os.path.join(path, \"fraudTest.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#import kagglehub\n",
    "\n",
    "# Download the dataset\n",
    "path = r\"/Users/nirjalagurung/fraud\"\n",
    "# List all files in the downloaded directory\n",
    "print(\"Files in dataset directory:\", os.listdir(path))\n",
    "\n",
    "# Load the CSV file (assuming it is named fraudTest.csv in the downloaded files)\n",
    "csv_path = os.path.join(path, \"fraudTest.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = df.dtypes\n",
    "print(\"\\nData Types:\\n\", data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Data': missing_data,\n",
    "    'Missing Percentage': missing_percentage\n",
    "}, index=df.columns)\n",
    "\n",
    "missing_df_filtered = missing_df[missing_df['Missing Data'] > 0]\n",
    "\n",
    "if not missing_df_filtered.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=missing_df_filtered.index, y=missing_df_filtered['Missing Percentage'], palette=\"viridis\")\n",
    "\n",
    "    for i, (value, pct) in enumerate(zip(missing_df_filtered['Missing Data'], missing_df_filtered['Missing Percentage'])):\n",
    "        ax.text(i, pct, f'{int(value)}', ha='center', va='bottom')\n",
    "\n",
    "    plt.ylabel('Percentage of Missing Values')\n",
    "    plt.title('Missing Data Analysis')\n",
    "    ax.set_xlabel('Features with Missing Values')\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_yscale('log')  \n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing data found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking is_fraud value 0 data values vs is_fraud value 1\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate the data by is_fraud values\n",
    "fraud_df = df[df['is_fraud'] == 1]\n",
    "non_fraud_df = df[df['is_fraud'] == 0]\n",
    "\n",
    "# Calculate means for numerical features by fraud type\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns.drop('is_fraud')\n",
    "fraud_means = fraud_df[numerical_columns].mean()\n",
    "non_fraud_means = non_fraud_df[numerical_columns].mean()\n",
    "\n",
    "# Plotting the comparisons\n",
    "fig, ax = plt.subplots(len(numerical_columns), 1, figsize=(12, len(numerical_columns) * 4))\n",
    "\n",
    "for i, col in enumerate(numerical_columns):\n",
    "    ax[i].bar(['Non-Fraud', 'Fraud'], [non_fraud_means[col], fraud_means[col]], color=['#1f77b4', '#ff7f0e'])\n",
    "    ax[i].set_title(f'Comparison of {col} for Non-Fraud vs Fraud')\n",
    "    ax[i].set_ylabel(col)\n",
    "    ax[i].set_xlabel('Transaction Type')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Filter rows with is_fraud equal to 1\n",
    "fraudulent_transactions = df[df['is_fraud'] == 1]\n",
    "\n",
    "# Display the rows with is_fraud == 1\n",
    "print(fraudulent_transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'is_fraud' column contains only 0 and 1\n",
    "unique_values = df['is_fraud'].unique()\n",
    "\n",
    "if set(unique_values) == {0, 1}:\n",
    "    print(\"The 'is_fraud' column is in the correct binary format (0 and 1) with no anomalies.\")\n",
    "else:\n",
    "    print(\"Anomalies found in 'is_fraud' column:\")\n",
    "    print(f\"Unexpected values: {unique_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outliers \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def find_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "outliers_dict = {}\n",
    "\n",
    "for col in numerical_columns:\n",
    "    if col != 'is_fraud':  # Skip the target column\n",
    "        outliers = find_outliers_iqr(df, col)\n",
    "        outliers_dict[col] = outliers\n",
    "        print(f\"{col}: {len(outliers)} outliers found.\")\n",
    "\n",
    "for col, outliers in outliers_dict.items():\n",
    "    if not outliers.empty:\n",
    "        # Strategy: Replace outliers with the median\n",
    "        median_value = df[col].median()\n",
    "        df.loc[(df[col] < outliers[col].min()) | (df[col] > outliers[col].max()), col] = median_value\n",
    "        print(f\"Outliers in column {col} replaced with median value: {median_value}\")\n",
    "\n",
    "#finding outliers with z score\n",
    "z_scores = df[numerical_columns].apply(zscore)\n",
    "outliers_z = (z_scores.abs() > 3).any(axis=1)\n",
    "outlier_rows = df[outliers_z]\n",
    "\n",
    "if outlier_rows.empty:\n",
    "    print(\"No outliers found using Z-score method.\")\n",
    "else:\n",
    "    print(f\"{len(outlier_rows)} rows identified as outliers using Z-score method.\")\n",
    "    # Strategy: Drop rows with Z-score outliers\n",
    "    df = df[~outliers_z]\n",
    "    print(\"Rows with Z-score outliers have been dropped.\")\n",
    "\n",
    "for col in numerical_columns:\n",
    "    if col != 'is_fraud':  # Skip the target column\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f\"Box Plot of {col} After Outlier Handling\")\n",
    "        plt.show()\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    print(f\"Unique values in {col}:\\n{df[col].value_counts()}\\n\")\n",
    "\n",
    "# writing cleaned dataset free/handling outliers \n",
    "df.to_csv(\"fraudTrain_processed.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers but a different visulization \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def find_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return len(outliers)\n",
    "\n",
    "# Selecting numerical columns\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Dictionary to store outlier counts\n",
    "outliers_count = {}\n",
    "\n",
    "# Calculate outlier counts using IQR\n",
    "for col in numerical_columns:\n",
    "    if col != 'is_fraud':  # Skip the target column\n",
    "        outliers_count[col] = find_outliers_iqr(df, col)\n",
    "\n",
    "# Convert to DataFrame for easy visualization\n",
    "outliers_df = pd.DataFrame(outliers_count.items(), columns=['Column', 'Outlier Count'])\n",
    "\n",
    "# Plot a bar graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=outliers_df, x='Column', y='Outlier Count', palette='viridis')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Number of Outliers in Each Column (IQR Method)\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Outlier Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chaning float into string for easier feasture selection\n",
    "\n",
    "# Print current data types\n",
    "data_types = df.dtypes\n",
    "#print(\"\\nData Types:\\n\", data_types)\n",
    "\n",
    "# Convert all float columns to strings\n",
    "float_columns = df.select_dtypes(include=['float64']).columns\n",
    "df[float_columns] = df[float_columns].astype(str)\n",
    "\n",
    "# Verify the conversion\n",
    "print(\"\\nUpdated Data Types:\\n\", df.dtypes)\n",
    "df.to_csv(\"fraudTrain_processed.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Feature Engineering\n",
    "unused_cols = ['Unnamed: 0', 'first', 'last', 'unix_time', 'street', 'gender', 'job', 'dob', 'city', 'state', 'trans_num', 'merchant']\n",
    "\n",
    "# Ensure all columns exist in the DataFrame before dropping\n",
    "unused_cols = [col for col in unused_cols if col in df.columns]\n",
    "df.drop(columns=unused_cols, inplace=True)\n",
    "\n",
    "# Check remaining DataFrame structure\n",
    "df.info()\n",
    "\n",
    "# Drop the original timestamp column after feature extraction\n",
    "df.drop(columns=['trans_date_trans_time'], inplace=True)\n",
    "\n",
    "# Encoding categorical columns\n",
    "encoder = LabelEncoder()\n",
    "if 'category' in df.columns:\n",
    "    df['category'] = encoder.fit_transform(df['category'])\n",
    "if 'cc_num' in df.columns:\n",
    "    df['cc_num'] = encoder.fit_transform(df['cc_num'])\n",
    "\n",
    "# Feature Scaling for numerical columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# List of numerical columns to scale\n",
    "scale_cols = ['amt', 'zip', 'city_pop']\n",
    "for col in scale_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = scaler.fit_transform(df[[col]])\n",
    "\n",
    "# Output the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Write to a new CSV file (optional)\n",
    "# Uncomment the line below to save the processed DataFrame to a CSV file\n",
    "df.to_csv(\"fraudTrain_processed.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
